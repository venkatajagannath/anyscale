# coding: utf-8

"""
    Managed Ray API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)  # noqa: E501

    The version of the OpenAPI document: 0.1.0
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from openapi_client.configuration import Configuration


class CreateFineTuningHyperparameters(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'n_epochs': 'int',
        'context_length': 'int'
    }

    attribute_map = {
        'n_epochs': 'n_epochs',
        'context_length': 'context_length'
    }

    def __init__(self, n_epochs=None, context_length=None, local_vars_configuration=None):  # noqa: E501
        """CreateFineTuningHyperparameters - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._n_epochs = None
        self._context_length = None
        self.discriminator = None

        if n_epochs is not None:
            self.n_epochs = n_epochs
        if context_length is not None:
            self.context_length = context_length

    @property
    def n_epochs(self):
        """Gets the n_epochs of this CreateFineTuningHyperparameters.  # noqa: E501

        Number of epochs to train for. Auto-calculated based on the training file size if not specified  # noqa: E501

        :return: The n_epochs of this CreateFineTuningHyperparameters.  # noqa: E501
        :rtype: int
        """
        return self._n_epochs

    @n_epochs.setter
    def n_epochs(self, n_epochs):
        """Sets the n_epochs of this CreateFineTuningHyperparameters.

        Number of epochs to train for. Auto-calculated based on the training file size if not specified  # noqa: E501

        :param n_epochs: The n_epochs of this CreateFineTuningHyperparameters.  # noqa: E501
        :type: int
        """

        self._n_epochs = n_epochs

    @property
    def context_length(self):
        """Gets the context_length of this CreateFineTuningHyperparameters.  # noqa: E501

        Maximum number of tokens to be considered for each training example. Auto-calculated based on the P95 sequence length of all training examples if not specified  # noqa: E501

        :return: The context_length of this CreateFineTuningHyperparameters.  # noqa: E501
        :rtype: int
        """
        return self._context_length

    @context_length.setter
    def context_length(self, context_length):
        """Sets the context_length of this CreateFineTuningHyperparameters.

        Maximum number of tokens to be considered for each training example. Auto-calculated based on the P95 sequence length of all training examples if not specified  # noqa: E501

        :param context_length: The context_length of this CreateFineTuningHyperparameters.  # noqa: E501
        :type: int
        """
        allowed_values = [512, 1024, 2048, 4096, 8192, 16384]  # noqa: E501
        if self.local_vars_configuration.client_side_validation and context_length not in allowed_values:  # noqa: E501
            raise ValueError(
                "Invalid value for `context_length` ({0}), must be one of {1}"  # noqa: E501
                .format(context_length, allowed_values)
            )

        self._context_length = context_length

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, CreateFineTuningHyperparameters):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, CreateFineTuningHyperparameters):
            return True

        return self.to_dict() != other.to_dict()
